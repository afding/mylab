<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML>
<HEAD>
<META NAME="generator" CONTENT="http://txt2tags.org">
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
</HEAD>
<BODY>

<DIV CLASS="header" ID="header">
</DIV>

<DIV CLASS="toc">

  <UL>
  <LI><A HREF="#toc1">1. 功能</A>
  <LI><A HREF="#toc2">2. 技术</A>
  <LI><A HREF="#toc3">3. 自动生成人名对照</A>
  </UL>

</DIV>
<DIV CLASS="body" ID="body">

<A NAME="toc1"></A>
<H1>1. 功能</H1>

<P>
给中文文本加英文索引。之前看冰与火之歌的小说，人名很多，发现看英文名更方便。于是做了这个web应用。可以修改/编辑索引。从本机选某个中文txt上传。就可以看到英文修饰的了。
</P>
<P>
最初发布在豆瓣小组中:
<A HREF="http://www.douban.com/group/topic/32220888/">http://www.douban.com/group/topic/32220888/</A>
</P>
<P>
目前可用的中英文索引表，只有《冰与火之歌》，主要是从网上搜集然后手工整理，内容在：
<A HREF="/worddict">worddict</A>
</P>

<A NAME="toc2"></A>
<H1>2. 技术</H1>

<P>
用nginx+pyramid搭建的web server。 deploy在免费的AWS-EC2上，硬件性能不高。
</P>
<P>
-web前端借用jqueryUI；
</P>

<UL>
<LI>为方便交换，将操作放在同一页面；用ajax上传/返回文字内容；
<LI>不提高下载，避免成为web存储，也规避了版权问题。
<LI>因为user较少，为方便，没有使用sign in方法，用户共享一份索引表。当人数增大，将采用OAuth方法，目前已有开源模块可用：velruse（<A HREF="http://packages.python.org/velruse/">http://packages.python.org/velruse/</A>）。
<P></P>
已尝试网站：
<A HREF="/login">login</A>
</UL>

<A NAME="toc3"></A>
<H1>3. 自动生成人名对照</H1>

<P>
根据输入的中文/英文文本，自动生成对照索引。目前代码实现的正确率略高于80%；
performance约为15min，笔记本电脑运行，对于一册8万字中文文本。 其中生成词库约半分钟。大部分时间在中英文词匹配， 100英文词*2k中文词。
</P>
<P>
某册《冰与火之歌》的运行结果见：
<A HREF="/static/worddict.res.txt">worddict.res.txt</A>
</P>
<P>
格式：
英文名：频率， 中文名：distance：距离（误差）
</P>
<P>
e.g.:
Aegon:57, 伊耿:distance:130
</P>
<P>
因为比较耗时，所以没有开放成API。
</P>
<P>
主要方法是先对中文分词，再使用一元线性回归，对可能的中英文词匹配，求最优值。对一些关联词做了附加处理，比如复数形式，字串。
因为多数人命是不非常用词，用固定词库的分词工具无法区分。这里用自己之前编写的自动生成词库的模块。
</P>
<P>
误差的主要问题是有些名字的翻译不是严格对应，中英文词的列表长度不等。目前是简单忽略掉尾部多出的词，而线性回归对错位造成的误差敏感；如果尝试忽略所有可能的位置，计算量较大，所以没有采用。
</P>
</DIV>

<!-- html code generated by txt2tags 2.6 (http://txt2tags.org) -->
<!-- cmdline: txt2tags about.me.t2t -->
</BODY></HTML>
